# Unified Multimodal System ğŸ¤–ğŸŒ

## Overview

The **Unified Multimodal System** is a cutting-edge **Gen-AI** framework that leverages the **Retrieval-Augmented Generation (RAG)** architecture to efficiently process and analyze multiple data modalities such as **PDFs**, **audio**, and **images**. This system integrates various modern technologies to enable seamless multimodal retrieval and processing. ğŸš€

With features like **audio generation**, **text-to-speech**, and **intelligent multimodal retrieval**, the system provides powerful AI-driven solutions for various applications. ğŸ”ğŸ§ğŸ“„

## Features

- **Multimodal Processing** ğŸ§ :
  - Supports the analysis and retrieval of information from **PDFs**, **audio**, and **images**. ğŸ—‚ï¸ğŸ§ğŸ“¸
  - Efficiently processes data through intelligent integration of AI models and retrieval techniques.

- **Efficient Retrieval and Analysis** âš™ï¸:
  - Utilizes **LangChain** for orchestrating workflows and interacting with different data sources.
  - **Sentence-Transformers** and **Chroma DB** power the semantic search and retrieval process. ğŸ”
  - **MultiQuery-Retriever** improves the efficiency of data retrieval from multiple sources simultaneously. ğŸ› ï¸

- **Audio Generation and Text-to-Speech** ğŸ¤:
  - Integrated with **Gemini** and **GTTS** (Google Text-to-Speech) for generating high-quality speech from text. ğŸ—£ï¸

- **Streamlit Interface** ğŸŒ:
  - A user-friendly web interface built using **Streamlit** that allows easy interaction with the system.

## Tech Stack ğŸ› ï¸

- **Programming Language**: Python ğŸ

- **Key Libraries & Frameworks**:
  - **LangChain**: For chaining language models and creating advanced workflows.
  - **Chroma DB**: A vector database for semantic search and indexing. ğŸ”¥
  - **GTTS (Google Text-to-Speech)**: For converting text into natural-sounding speech.
  - **HuggingFace**: For transformer-based models and APIs.
  - **Streamlit**: For creating the frontend interface.

## Installation ğŸ’»

### Prerequisites
Make sure you have **Python 3.x** installed.

1. Clone this repository:

```
git clone https://github.com/yourusername/Unified-Multimodal-System.git
cd Unified-Multimodal-System
```

2. Install the required dependencies:

``` 
pip install -r requirements.txt
```

## Running the System ğŸš€
- To launch the Streamlit interface, run the following command:
```
streamlit run UI.py
```

## How It Works ğŸ¤–ğŸ”
- Data Ingestion: Upload your PDF, audio, or image to the system.

- Multimodal Analysis: The system processes the data using integrated models for retrieval and generation.

- Results: The processed information is displayed or spoken (for audio) through the Streamlit interface.

## Contributing ğŸ¤
We welcome contributions! If you'd like to contribute to the project, feel free to open an issue or submit a pull request. Make sure to fork the repo and follow the contributing guidelines.

## ğŸ“¬ Connect with Me
If you like this project or want to collaborate, feel free to reach out!

ğŸ“§ Email: kicha2003e@gmail.com

ğŸ’¼ LinkedIn: [Join my network](www.linkedin.com/in/kishore-thedeveloper)

ğŸ™ GitHub: [Profile Link](https://github.com/Kishore003E)
